{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from astropy.io import fits\n",
    "%config InlineBackend.rc = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are to be used in the case that I transform my FITS image files into JPGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: efigi-images/psf_i/psf_PGC0000212_i.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  chip01        1 PrimaryHDU      19   (45, 45)   float32   \n"
     ]
    }
   ],
   "source": [
    "hdu_list = fits.open('efigi-images/psf_i/psf_PGC0000212_i.fits')\n",
    "hdu_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us there are no ASCII tables containing data within the FITS headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Data\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('images/train',\n",
    "                                                    target_size=(,),\n",
    "                                                    class_mode='categorical'\n",
    "                                                   )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('images_test',\n",
    "                                                  target_size=(,),\n",
    "                                                  class_mode='categorical'\n",
    "                                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Build\n",
    "\n",
    "fsm_model = Sequential()\n",
    "fsm_model.add(ConvD(64, (4,4), input_shape=(,,), activation='relu'))\n",
    "fsm_model.add(Flatten())\n",
    "fsm_model.add(Dense(units=64, activation='relu'))\n",
    "fsm_model.add(Dense(units=18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model\n",
    "\n",
    "fsm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "fsm_model.fit(x_train, y_train,\n",
    "         epochs=10,\n",
    "         verbose=0,\n",
    "         validation_data=(x_test, y_test))\n",
    "\n",
    "fsm_score = fsm_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with additional Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Build\n",
    "\n",
    "pool_model = Sequential()\n",
    "pool_model.add(Conv2D(32, (4,4), input_shape=(,,), activation='relu'))\n",
    "pool_model.add(Conv2D(64, (4,4), activation='relu'))\n",
    "pool_model.add(MaxPooling2D)\n",
    "pool_model.add(Conv2D(128))\n",
    "pool_model.add(MaxPooling2D)\n",
    "pool_model.add(Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model\n",
    "\n",
    "pool_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "pool_model.fit(x_train, y_train,\n",
    "         epochs=10,\n",
    "         verbose=0,\n",
    "         validation_data=(x_test, y_test))\n",
    "\n",
    "pool_score = pool_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project values on robust capabilities in handling edge cases, so we want to take extra care in protecting against overfitting. This iteration adds in two dropout layers, the first significant and the second less imposing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Build\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (4,4), input_shape=(,,), activation='relu'))\n",
    "model.add(Conv2D(64, (4,4), activation='relu'))\n",
    "model.add(MaxPooling2D)\n",
    "model.add(Conv2D(128))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
